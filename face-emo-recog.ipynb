{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from sklearn.metrics import pairwise_distances, log_loss, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import datasets, preprocessing,cross_validation, feature_extraction\n",
    "from sklearn import linear_model, svm, metrics, ensemble, tree, ensemble\n",
    "from sklearn.decomposition import PCA\n",
    "import urllib\n",
    "import csv\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from collections import Counter\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import pandas\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "facecascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "facedict = {}\n",
    "actions = {}\n",
    "emotions = [\"anger\",\"disgust\",\"fear\", \"happy\",\"neutral\",\"sadness\",\"surprise\"]\n",
    "df = pandas.read_excel(\"emotion_audio.xlsx\") \n",
    "actions[\"anger\"] = [x for x in df.anger.dropna()] \n",
    "actions[\"disgust\"] = [x for x in df.disgust.dropna()]\n",
    "actions[\"fear\"] = [x for x in df.fear.dropna()]\n",
    "actions[\"happy\"] = [x for x in df.happy.dropna()]\n",
    "actions[\"neutral\"] = [x for x in df.neutral.dropna()]\n",
    "actions[\"sadness\"] = [x for x in df.sadness.dropna()]\n",
    "actions[\"surprise\"] = [x for x in df.surprise.dropna()]\n",
    "\n",
    "\n",
    "def open_stuff(filename): \n",
    "    if sys.platform == \"win32\":\n",
    "        os.startfile(filename)\n",
    "    else:\n",
    "        opener =\"open\" if sys.platform == \"darwin\" else \"xdg-open\"\n",
    "        subprocess.call([opener, filename])\n",
    "\n",
    "def crop_face(clahe_image, face):\n",
    "    for (x, y, w, h) in face:\n",
    "        faceslice = clahe_image[y:y+h, x:x+w]\n",
    "        faceslice = cv2.resize(faceslice, (350, 350))\n",
    "    facedict[\"face%s\" %(len(facedict)+1)] = faceslice\n",
    "    return faceslice\n",
    "\n",
    "def update_model(emotions):\n",
    "    print(\"Model update mode active\")\n",
    "    check_folders(emotions)\n",
    "    for i in range(0, len(emotions)):\n",
    "        save_face(emotions[i])\n",
    "    print(\"collected images, looking good! Now updating model...\")\n",
    "    print(\"Done!\")\n",
    "    cv2.destroyWindow(\"preview\")\n",
    "    cv2.destroyWindow(\"webcam\")\n",
    "\n",
    "def check_folders(emotions): \n",
    "    for x in emotions:\n",
    "        if os.path.exists(\"sorted_set\\\\%s\" %x):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(\"sorted_set\\\\%s\" %x)\n",
    "\n",
    "def save_face(emotion):\n",
    "    print(\"\\n\\nplease look \" + emotion + \" when the timer expires and keep the expression stable until instructed otherwise.\")\n",
    "    actionlist = [x for x in actions[emotion]] \n",
    "    random.shuffle(actionlist) \n",
    "    open_stuff(actionlist[0])\n",
    "    for i in range(0,5):\n",
    "        print(5-i)\n",
    "        time.sleep(1)\n",
    "    while len(facedict.keys()) < 11:\n",
    "        grab_webcamframe()\n",
    "    for x in facedict.keys(): \n",
    "        cv2.imwrite(\"sorted_set\\\\%s\\\\%s.jpg\" %(emotion, len(glob.glob(\"sorted_set\\\\%s\\\\*\" %emotion))), facedict[x])\n",
    "    facedict.clear() \n",
    "\n",
    "def grab_webcamframe():\n",
    "      \n",
    "    while True:\n",
    "        if vc.isOpened(): \n",
    "            rval, frame = vc.read()\n",
    "        else:\n",
    "            rval = False\n",
    "        cv2.imshow(\"preview\", frame)\n",
    "        key = cv2.waitKey(40)\n",
    "        if key == 27: # exit on ESC\n",
    "            break\n",
    "        if key == 32:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Convert image to grayscale to improve detection speed and accuracy\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            clahe_image = clahe.apply(gray)\n",
    "\n",
    "            \n",
    "            face = facecascade.detectMultiScale(clahe_image, scaleFactor=1.1, minNeighbors=15, minSize=(10, 10), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "            for (x, y, w, h) in face: \n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2) \n",
    "\n",
    "            if len(face) == 1: \n",
    "                faceslice = crop_face(clahe_image, face)\n",
    "                cv2.imshow(\"webcam\", frame)\n",
    "                return faceslice\n",
    "            else:\n",
    "                print(\"no/multiple faces detected, passing over frame\")\n",
    "\n",
    "    cv2.destroyWindow(\"preview\")\n",
    "    cv2.destroyWindow(\"webcam\")\n",
    "\n",
    "update_model(emotions)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = np.load(\"data_features.npy\")\n",
    "target = np.load(\"data_labels.npy\")\n",
    "data.shape"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_y = [target[i].split('\\\\')[0] for i in range(target.shape[0])]\n",
    "type(data_y)\n",
    "data_y = pd.DataFrame(data_y)\n",
    "type(data_y)\n",
    "data_y.columns = ['label']\n",
    "Counter(data_y['label'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classes = {\"label\": {\"ger\": 0, \"sgust\": 1, \"ar\": 2, \"ppy\": 3,\n",
    "                                  \"utral\": 4, \"dness\": 5, \"rprise\":6 }}\n",
    "data_y.replace(classes, inplace=True)\n",
    "print(data_y.head())\n",
    "print(type(data_y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, test_df, y_train, y_test = train_test_split(data, data_y, stratify=data_y, test_size=0.05)\n",
    "train_df, cv_df, y_train, y_cv = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)\n",
    "print(train_df.shape)\n",
    "print(cv_df.shape)\n",
    "print(test_df.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_class_distribution = y_train['label'].value_counts().sortlevel()\n",
    "test_class_distribution = y_test['label'].value_counts().sortlevel()\n",
    "cv_class_distribution = y_cv['label'].value_counts().sortlevel()\n",
    "\n",
    "my_colors = 'rgbkymc'\n",
    "train_class_distribution.plot(kind='bar', color=my_colors)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of yi in train data')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi = np.argsort(-train_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i, ':',train_class_distribution.values[i], '(', np.round((train_class_distribution.values[i]/train_df.shape[0]*100), 3), '%)')\n",
    "\n",
    "    \n",
    "print('-'*80)\n",
    "my_colors = 'rgbkymc'\n",
    "test_class_distribution.plot(kind='bar', color=my_colors)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of yi in test data')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi = np.argsort(-test_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i, ':',test_class_distribution.values[i], '(', np.round((test_class_distribution.values[i]/test_df.shape[0]*100), 3), '%)')\n",
    "\n",
    "print('-'*80)\n",
    "my_colors = 'rgbkymc'\n",
    "cv_class_distribution.plot(kind='bar', color=my_colors)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of yi in cross validation data')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi = np.argsort(-train_class_distribution.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class', i, ':',cv_class_distribution.values[i], '(', np.round((cv_class_distribution.values[i]/cv_df.shape[0]*100), 3), '%)')\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    B =(C/C.sum(axis=0))\n",
    "    \n",
    "    labels = [0,1,2,3,4,5,6]\n",
    "\n",
    "    print(\"-\"*20, \"Confusion matrix\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(C, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*20, \"Precision matrix (Columm Sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(B, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*20, \"Recall matrix (Row sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(A, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_data_len = test_df.shape[0]\n",
    "cv_data_len = cv_df.shape[0]\n",
    "\n",
    "cv_predicted_y = np.zeros((cv_data_len,7))\n",
    "for i in range(cv_data_len):\n",
    "    rand_probs = np.random.rand(1,7)\n",
    "    cv_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Cross Validation Data using Random Model\",log_loss(y_cv,cv_predicted_y, eps=1e-15))\n",
    "\n",
    "test_predicted_y = np.zeros((test_data_len,7))\n",
    "for i in range(test_data_len):\n",
    "    rand_probs = np.random.rand(1,7)\n",
    "    test_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Test Data using Random Model\",log_loss(y_test,test_predicted_y, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(test_predicted_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha = [10 ** x for x in range(-5, 1)]\n",
    "cv_log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n",
    "    clf.fit(train_df, y_train)\n",
    "    \n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_df, y_train)\n",
    "    predict_y = sig_clf.predict_proba(cv_df)\n",
    "    \n",
    "    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\n",
    "clf.fit(train_df, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_df, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(predict_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alpha = [10 ** x for x in range(-5, 1)]\n",
    "cv_log_error_array=[]\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i, penalty='l2', loss='hinge', random_state=42)\n",
    "    clf.fit(train_df, y_train)\n",
    "    \n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_df, y_train)\n",
    "    predict_y = sig_clf.predict_proba(cv_df)\n",
    "    \n",
    "    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "    print('For values of alpha = ', i, \"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, cv_log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='hinge', random_state=42)\n",
    "clf.fit(train_df, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "sig_clf.fit(train_df, y_train)\n",
    "\n",
    "predict_y = sig_clf.predict_proba(train_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(cv_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "predict_y = sig_clf.predict_proba(test_df)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(predict_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "\n",
    "def save_webcam_features():\n",
    "    img_width, img_height = 350, 350\n",
    "    top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "    train_data_dir = 'real_set'\n",
    "\n",
    "    nb_train_samples = 1\n",
    "\n",
    "    epochs = 50\n",
    "    batch_size = 1\n",
    "    \n",
    "    #Function to compute VGG-16 CNN for image feature extraction.\n",
    "    train_target = []\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    generator_train = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    for i in generator_train.filenames:\n",
    "        train_target.append(i[2:])\n",
    "     \n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(generator_train, nb_train_samples // batch_size)\n",
    "   \n",
    "    bottleneck_features_train =  bottleneck_features_train.reshape(1,51200)\n",
    "    print(bottleneck_features_train.shape)\n",
    "    np.save(open('real_features.npy', 'wb'), bottleneck_features_train)\n",
    "    np.save(open('real_labels.npy', 'wb'), np.array(train_target))\n",
    "    prediction()\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def prediction():\n",
    "    predictions = []\n",
    "    features = np.load('real_features.npy')\n",
    "    labels = np.load('real_labels.npy')\n",
    "    predictions  = sig_clf.predict_proba(features)\n",
    "    \n",
    "    print(predictions)\n",
    "    emotion = []\n",
    "    emotion = sig_clf.predict(features)\n",
    "\n",
    "    cv2.destroyWindow(\"preview\")"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "facecascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def crop_face(clahe_image, face):\n",
    "    for (x, y, w, h) in face:\n",
    "        faceslice = clahe_image[y:y+h, x:x+w]\n",
    "        faceslice = cv2.resize(faceslice, (350, 350))\n",
    "    facedict[\"face%s\" %(len(facedict)+1)] = faceslice\n",
    "    return faceslice\n",
    "\n",
    "while True:\n",
    "    facedict = {}\n",
    "    if vc.isOpened(): \n",
    "        rval, frame = vc.read()\n",
    "    else:\n",
    "        rval = False\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    key = cv2.waitKey(40)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Convert image to grayscale to improve detection speed and accuracy\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_image = clahe.apply(gray)\n",
    "    face = facecascade.detectMultiScale(clahe_image, scaleFactor=1.1, minNeighbors=15, minSize=(10, 10), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    for (x, y, w, h) in face:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    if len(face) == 1: \n",
    "        faceslice = crop_face(clahe_image, face)\n",
    "\n",
    "            \n",
    "        for x in facedict.keys():\n",
    "            cv2.imwrite(\"real_set\\\\1\\\\%s.jpg\" %x, facedict[x])\n",
    "            save_webcam_features()\n",
    "        \n",
    "cv2.destroyWindow(\"preview\")\n",
    "#cv2.destroyWindow(\"webcam\")\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}